{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc6340705207425a841babcab25771f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9377552a1b6e48949d81f9adfcccacd0",
              "IPY_MODEL_074b90f8294547f6a3291fe603db4dd3",
              "IPY_MODEL_e436125c697744e5ad8a0772855de585"
            ],
            "layout": "IPY_MODEL_fdec903d48044e7aa8905ff1f5bdc1a9"
          }
        },
        "9377552a1b6e48949d81f9adfcccacd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca3e61ebf7fe453e83ef7b726b27aee5",
            "placeholder": "​",
            "style": "IPY_MODEL_d650d727f5d34106a1905147f945b001",
            "value": "Downloading data: 100%"
          }
        },
        "074b90f8294547f6a3291fe603db4dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b4d3a08d7544628b85ea7079470bf0",
            "max": 3805000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5c1df0c7264b1898cca1a6fe11c21c",
            "value": 3805000
          }
        },
        "e436125c697744e5ad8a0772855de585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7705d722baf149fd9a81550509336457",
            "placeholder": "​",
            "style": "IPY_MODEL_3f18fac1c9ff4231bd0c0554df120e6e",
            "value": " 3.81M/3.81M [00:01&lt;00:00, 2.62MB/s]"
          }
        },
        "fdec903d48044e7aa8905ff1f5bdc1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3e61ebf7fe453e83ef7b726b27aee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d650d727f5d34106a1905147f945b001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45b4d3a08d7544628b85ea7079470bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5c1df0c7264b1898cca1a6fe11c21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7705d722baf149fd9a81550509336457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f18fac1c9ff4231bd0c0554df120e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd1eeb29a8b64f2582f9af59b5f3da24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_931bea4c2a5640729660b99b40435699",
              "IPY_MODEL_ba2c2e73a267467f97bc6e1e5e4adfb8",
              "IPY_MODEL_0aed1cab94eb4c0cb22014f382fa28b2"
            ],
            "layout": "IPY_MODEL_92535a5aa6c7407db8548bda001f8797"
          }
        },
        "931bea4c2a5640729660b99b40435699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b1b8e1d384492b98f1999a9dd0d5b9",
            "placeholder": "​",
            "style": "IPY_MODEL_1227659700674c0fa82df05b393fc12e",
            "value": "Downloading data: 100%"
          }
        },
        "ba2c2e73a267467f97bc6e1e5e4adfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3482ffb1d9140bb8befe8c03548cd8c",
            "max": 295907,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbd7b653ec6d4446b9907c2b854881a4",
            "value": 295907
          }
        },
        "0aed1cab94eb4c0cb22014f382fa28b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34f94ed4182349089c6fc4f59ce74c5c",
            "placeholder": "​",
            "style": "IPY_MODEL_f1732901e6a44d9184ce2fd47bf26e3a",
            "value": " 296k/296k [00:00&lt;00:00, 410kB/s]"
          }
        },
        "92535a5aa6c7407db8548bda001f8797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b1b8e1d384492b98f1999a9dd0d5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1227659700674c0fa82df05b393fc12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3482ffb1d9140bb8befe8c03548cd8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd7b653ec6d4446b9907c2b854881a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34f94ed4182349089c6fc4f59ce74c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1732901e6a44d9184ce2fd47bf26e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2152387678464d8abbf2a1a0cabcb06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9574fcc15d24429884cc659928703b18",
              "IPY_MODEL_2cec5fdc408f428d95cbf5b19b059429",
              "IPY_MODEL_2ec5a88a811548c797dfd78067fc00a8"
            ],
            "layout": "IPY_MODEL_a4e907b51d774ac9a6e0e6696ef47501"
          }
        },
        "9574fcc15d24429884cc659928703b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fcafa76e0d041d89de7e63c066a19ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0d7e45cc78a84113966e6986bc060494",
            "value": "Downloading data: 100%"
          }
        },
        "2cec5fdc408f428d95cbf5b19b059429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb93f0d3fd0741bfab0cbeb35148e4b5",
            "max": 293375,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84c0c2f6f8f849f09be3ad3d6d85fdee",
            "value": 293375
          }
        },
        "2ec5a88a811548c797dfd78067fc00a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c4064a6f634ca994edd5365fca31ec",
            "placeholder": "​",
            "style": "IPY_MODEL_30ba8fd9089a4df087878d3988573b84",
            "value": " 293k/293k [00:00&lt;00:00, 413kB/s]"
          }
        },
        "a4e907b51d774ac9a6e0e6696ef47501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fcafa76e0d041d89de7e63c066a19ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7e45cc78a84113966e6986bc060494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb93f0d3fd0741bfab0cbeb35148e4b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c0c2f6f8f849f09be3ad3d6d85fdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67c4064a6f634ca994edd5365fca31ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ba8fd9089a4df087878d3988573b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03e880a1ebf245cba2798bb1efadc5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471aa1a9dd6348cf975afec70b7189e2",
              "IPY_MODEL_41c60e16e03040acbe0205063d1d854c",
              "IPY_MODEL_084166b1d7eb4aedb12e2001d48a7337"
            ],
            "layout": "IPY_MODEL_860d22fc0dae4166aa4b36eb32b159e0"
          }
        },
        "471aa1a9dd6348cf975afec70b7189e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae7758248db4c42ad523b799ae3100b",
            "placeholder": "​",
            "style": "IPY_MODEL_58d8bd01a7f74339930b1416175ebf96",
            "value": "Generating train split: 100%"
          }
        },
        "41c60e16e03040acbe0205063d1d854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1d18ff6f910423cb141846ee523944b",
            "max": 15014,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec7431d22a9d473caa53d4e991f0a3dc",
            "value": 15014
          }
        },
        "084166b1d7eb4aedb12e2001d48a7337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb88a6e1bf2a425da337416d9da13640",
            "placeholder": "​",
            "style": "IPY_MODEL_75dffbc6fcd640d2a8e29b679a26b255",
            "value": " 15014/15014 [00:00&lt;00:00, 39061.68 examples/s]"
          }
        },
        "860d22fc0dae4166aa4b36eb32b159e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae7758248db4c42ad523b799ae3100b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d8bd01a7f74339930b1416175ebf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1d18ff6f910423cb141846ee523944b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7431d22a9d473caa53d4e991f0a3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb88a6e1bf2a425da337416d9da13640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dffbc6fcd640d2a8e29b679a26b255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a42cf80066f45a895968b2b20cec8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_582f7cbed0a243d4909c49ff660a5621",
              "IPY_MODEL_c8447713fa1444f89232e4c0dd60c858",
              "IPY_MODEL_ca7f17f1606e47129cac532d0542827b"
            ],
            "layout": "IPY_MODEL_9c4de3b880ee4ce7a08490e8bdc05831"
          }
        },
        "582f7cbed0a243d4909c49ff660a5621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e194e9b494f644c087fd6da73188bec1",
            "placeholder": "​",
            "style": "IPY_MODEL_c21184c8c0da47bc99743dc5dcf5cf57",
            "value": "Generating validation split: 100%"
          }
        },
        "c8447713fa1444f89232e4c0dd60c858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a4cb2f107548f3b38c0072ce1c378b",
            "max": 1019,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_799469d0e2ba402198bd87a6b0e806b4",
            "value": 1019
          }
        },
        "ca7f17f1606e47129cac532d0542827b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2e98a8bfc2480e8e404a30b05ad0a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f96c8ac78ac7422ba07c5bd63a0a822d",
            "value": " 1019/1019 [00:00&lt;00:00, 11835.00 examples/s]"
          }
        },
        "9c4de3b880ee4ce7a08490e8bdc05831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e194e9b494f644c087fd6da73188bec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21184c8c0da47bc99743dc5dcf5cf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a4cb2f107548f3b38c0072ce1c378b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799469d0e2ba402198bd87a6b0e806b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a2e98a8bfc2480e8e404a30b05ad0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96c8ac78ac7422ba07c5bd63a0a822d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7cb30a5ce644d1a408604e4fac466d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13bcda90fedc47d3a9d6e9e52e0c0026",
              "IPY_MODEL_3eaae43702954f97a9f7cc21959cb04f",
              "IPY_MODEL_9c9383ef4f9e4e31b3c805b728da8d2e"
            ],
            "layout": "IPY_MODEL_63e45a5240dc49e6bfaa812cd26b94d6"
          }
        },
        "13bcda90fedc47d3a9d6e9e52e0c0026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d98663e0b4b40eab31f2d5c88bf70fc",
            "placeholder": "​",
            "style": "IPY_MODEL_6b7aab8e6de641669e03c610941629af",
            "value": "Generating test split: 100%"
          }
        },
        "3eaae43702954f97a9f7cc21959cb04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb91e75e118473291cea87177dc0caa",
            "max": 1047,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_761f1f5062324f1c917c54999686dd54",
            "value": 1047
          }
        },
        "9c9383ef4f9e4e31b3c805b728da8d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_814b634da1f44284ade94dc2664e93e4",
            "placeholder": "​",
            "style": "IPY_MODEL_4ca3476f86f3464f87c9192915110b2d",
            "value": " 1047/1047 [00:00&lt;00:00, 17920.94 examples/s]"
          }
        },
        "63e45a5240dc49e6bfaa812cd26b94d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d98663e0b4b40eab31f2d5c88bf70fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7aab8e6de641669e03c610941629af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb91e75e118473291cea87177dc0caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761f1f5062324f1c917c54999686dd54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "814b634da1f44284ade94dc2664e93e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca3476f86f3464f87c9192915110b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random as rd\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "!pip install datasets\n",
        "!pip install conllu\n",
        "\n",
        "import torch\n",
        "from functools import partial\n",
        "from datasets import load_dataset\n",
        "\n",
        "!pip install evaluate\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\"\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.env_util import make_vec_env"
      ],
      "metadata": {
        "id": "ekoJ290XFdKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac1ec7a-a4d2-4e53-f23e-4a6c640bab72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/536.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/536.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.17.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-15.0.0\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.5.3\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
            "Collecting stable-baselines3[extra]>=2.0.0a4\n",
            "  Downloading stable_baselines3-2.3.0a2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.1.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (13.7.0)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a4) (4.9.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a4)\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]>=2.0.0a4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]>=2.0.0a4) (2023.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a4) (6.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a4) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=028a6d4dd2c2777815de05213f20284b1a8a48ad15b8840be01050e5cc757320\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: farama-notifications, gymnasium, ale-py, shimmy, AutoROM.accept-rom-license, autorom, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 shimmy-1.3.0 stable-baselines3-2.3.0a2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the function returns whether a tree is projective or not. It is currently\n",
        "# implemented inefficiently by brute checking every pair of arcs.\n",
        "def is_projective(tree):\n",
        "  for i in range(len(tree)):\n",
        "    if tree[i] == -1:\n",
        "      continue\n",
        "    left = min(i, tree[i])\n",
        "    right = max(i, tree[i])\n",
        "\n",
        "    for j in range(0, left):\n",
        "      if tree[j] > left and tree[j] < right:\n",
        "        return False\n",
        "    for j in range(left+1, right):\n",
        "      if tree[j] < left or tree[j] > right:\n",
        "        return False\n",
        "    for j in range(right+1, len(tree)):\n",
        "      if tree[j] > left and tree[j] < right:\n",
        "        return False\n",
        "\n",
        "  return True\n",
        "\n",
        "# the function creates a dictionary of word/index pairs: our embeddings vocabulary\n",
        "# threshold is the minimum number of appearance for a token to be included in the embedding list\n",
        "def create_dict(dataset, threshold=3):\n",
        "  dic = {}  # dictionary of word counts\n",
        "  for sample in dataset:\n",
        "    for word in sample['tokens']:\n",
        "      if word in dic:\n",
        "        dic[word] += 1\n",
        "      else:\n",
        "        dic[word] = 1\n",
        "\n",
        "  map = {}  # dictionary of word/index pairs. This is our embedding list\n",
        "  map[\"<pad>\"] = 0\n",
        "  map[\"<ROOT>\"] = 1\n",
        "  map[\"<unk>\"] = 2 #used for words that do not appear in our list\n",
        "\n",
        "  next_indx = 3\n",
        "  for word in dic.keys():\n",
        "    if dic[word] >= threshold:\n",
        "      map[word] = next_indx\n",
        "      next_indx += 1\n",
        "\n",
        "  return map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddic3f8cL1kK",
        "outputId": "a7b51185-26e3-4a41-ee49-5999b7e6eaee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset('universal_dependencies', 'grc_proiel', split=\"train\")\n",
        "dev_dataset = load_dataset('universal_dependencies', 'grc_proiel', split=\"validation\")\n",
        "test_dataset = load_dataset('universal_dependencies', 'grc_proiel', split=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "dc6340705207425a841babcab25771f8",
            "9377552a1b6e48949d81f9adfcccacd0",
            "074b90f8294547f6a3291fe603db4dd3",
            "e436125c697744e5ad8a0772855de585",
            "fdec903d48044e7aa8905ff1f5bdc1a9",
            "ca3e61ebf7fe453e83ef7b726b27aee5",
            "d650d727f5d34106a1905147f945b001",
            "45b4d3a08d7544628b85ea7079470bf0",
            "9d5c1df0c7264b1898cca1a6fe11c21c",
            "7705d722baf149fd9a81550509336457",
            "3f18fac1c9ff4231bd0c0554df120e6e",
            "fd1eeb29a8b64f2582f9af59b5f3da24",
            "931bea4c2a5640729660b99b40435699",
            "ba2c2e73a267467f97bc6e1e5e4adfb8",
            "0aed1cab94eb4c0cb22014f382fa28b2",
            "92535a5aa6c7407db8548bda001f8797",
            "c1b1b8e1d384492b98f1999a9dd0d5b9",
            "1227659700674c0fa82df05b393fc12e",
            "f3482ffb1d9140bb8befe8c03548cd8c",
            "bbd7b653ec6d4446b9907c2b854881a4",
            "34f94ed4182349089c6fc4f59ce74c5c",
            "f1732901e6a44d9184ce2fd47bf26e3a",
            "2152387678464d8abbf2a1a0cabcb06e",
            "9574fcc15d24429884cc659928703b18",
            "2cec5fdc408f428d95cbf5b19b059429",
            "2ec5a88a811548c797dfd78067fc00a8",
            "a4e907b51d774ac9a6e0e6696ef47501",
            "8fcafa76e0d041d89de7e63c066a19ec",
            "0d7e45cc78a84113966e6986bc060494",
            "bb93f0d3fd0741bfab0cbeb35148e4b5",
            "84c0c2f6f8f849f09be3ad3d6d85fdee",
            "67c4064a6f634ca994edd5365fca31ec",
            "30ba8fd9089a4df087878d3988573b84",
            "03e880a1ebf245cba2798bb1efadc5ff",
            "471aa1a9dd6348cf975afec70b7189e2",
            "41c60e16e03040acbe0205063d1d854c",
            "084166b1d7eb4aedb12e2001d48a7337",
            "860d22fc0dae4166aa4b36eb32b159e0",
            "3ae7758248db4c42ad523b799ae3100b",
            "58d8bd01a7f74339930b1416175ebf96",
            "f1d18ff6f910423cb141846ee523944b",
            "ec7431d22a9d473caa53d4e991f0a3dc",
            "eb88a6e1bf2a425da337416d9da13640",
            "75dffbc6fcd640d2a8e29b679a26b255",
            "2a42cf80066f45a895968b2b20cec8db",
            "582f7cbed0a243d4909c49ff660a5621",
            "c8447713fa1444f89232e4c0dd60c858",
            "ca7f17f1606e47129cac532d0542827b",
            "9c4de3b880ee4ce7a08490e8bdc05831",
            "e194e9b494f644c087fd6da73188bec1",
            "c21184c8c0da47bc99743dc5dcf5cf57",
            "f4a4cb2f107548f3b38c0072ce1c378b",
            "799469d0e2ba402198bd87a6b0e806b4",
            "0a2e98a8bfc2480e8e404a30b05ad0a4",
            "f96c8ac78ac7422ba07c5bd63a0a822d",
            "1e7cb30a5ce644d1a408604e4fac466d",
            "13bcda90fedc47d3a9d6e9e52e0c0026",
            "3eaae43702954f97a9f7cc21959cb04f",
            "9c9383ef4f9e4e31b3c805b728da8d2e",
            "63e45a5240dc49e6bfaa812cd26b94d6",
            "5d98663e0b4b40eab31f2d5c88bf70fc",
            "6b7aab8e6de641669e03c610941629af",
            "efb91e75e118473291cea87177dc0caa",
            "761f1f5062324f1c917c54999686dd54",
            "814b634da1f44284ade94dc2664e93e4",
            "4ca3476f86f3464f87c9192915110b2d"
          ]
        },
        "id": "NgcWnOb3L2rk",
        "outputId": "9185ee25-80f8-4754-9fca-03358631295c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.81M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc6340705207425a841babcab25771f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/296k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd1eeb29a8b64f2582f9af59b5f3da24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/293k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2152387678464d8abbf2a1a0cabcb06e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/15014 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03e880a1ebf245cba2798bb1efadc5ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1019 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a42cf80066f45a895968b2b20cec8db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1047 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e7cb30a5ce644d1a408604e4fac466d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the non projective trees in the train dataset\n",
        "#train_dataset = [sample for sample in train_dataset if is_projective([-1] + [int(head) for head in sample[\"head\"]])]\n",
        "\n",
        "# create the embedding dictionary\n",
        "emb_dictionary = create_dict(train_dataset)"
      ],
      "metadata": {
        "id": "2HIAjKTUMFU2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sample(sample, get_gold_path = False):\n",
        "\n",
        "  # put sentence and gold tree in our format\n",
        "  sentence = [\"<ROOT>\"] + sample[\"tokens\"]\n",
        "  gold = [-1] + [int(i) for i in sample[\"head\"]]  #heads in the gold tree are strings, we convert them to int\n",
        "\n",
        "  # embedding ids of sentence words\n",
        "  enc_sentence = [emb_dictionary[word] if word in emb_dictionary else emb_dictionary[\"<unk>\"] for word in sentence]\n",
        "\n",
        "  return enc_sentence, sentence, gold"
      ],
      "metadata": {
        "id": "15lL5uOoMUdW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(batch_data):\n",
        "  data = [process_sample(s) for s in batch_data]\n",
        "  # sentences, paths, moves, trees are parallel arrays, each element refers to a sentence\n",
        "  enc_sentences = [s[0] for s in data] # input_ids\n",
        "  sentences = [s[1] for s in data] # sentences\n",
        "  trees = [s[2] for s in data] # gold_tree\n",
        "  return enc_sentences, sentences, trees"
      ],
      "metadata": {
        "id": "5k1agfEuMWuJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "\n",
        "bilstm_train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=partial(prepare_batch))\n",
        "bilstm_dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch))\n",
        "bilstm_test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=partial(prepare_batch))"
      ],
      "metadata": {
        "id": "_JekKSrGMY_f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qkSOn1vwro4g"
      },
      "outputs": [],
      "source": [
        "class PrioritizedReplayBuffer():\n",
        "  def __init__(self, max_size, input_shape, alpha=0.9):\n",
        "    \"\"\"\n",
        "    Initialize the Prioritized Replay Buffer.\n",
        "\n",
        "    Args:\n",
        "        max_size (int): The maximum size of the buffer.\n",
        "        input_shape (tuple): The shape of the inputs.\n",
        "        alpha (float): Determines how much prioritization is used, with 0 corresponding to no prioritization.\n",
        "    \"\"\"\n",
        "    self.mem_size = max_size\n",
        "    self.mem_cntr = 0\n",
        "    self.alpha = alpha  # The exponent alpha determines how much prioritization is used\n",
        "\n",
        "    # Initialize memory for states, actions, rewards, terminal flags, and priorities\n",
        "    self.state_memory = np.zeros((self.mem_size, *input_shape), dtype=np.float32)\n",
        "    self.new_state_memory = np.zeros((self.mem_size, *input_shape), dtype=np.float32)\n",
        "    self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n",
        "    self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "    self.terminal_memory = np.zeros(self.mem_size, dtype=np.uint8)\n",
        "    self.priority_memory = np.zeros(self.mem_size, dtype=np.float32) + 1e-5  # Initialize with small positive values\n",
        "    self.max_priority = 1.0  # Initial max priority\n",
        "\n",
        "  def store_transition(self, state, action, reward, state_, done):\n",
        "    \"\"\"\n",
        "    Store a transition in the buffer.\n",
        "\n",
        "    Args:\n",
        "        state: The state of the environment before the action.\n",
        "        action: The action taken.\n",
        "        reward: The reward received.\n",
        "        state_: The state of the environment after the action.\n",
        "        done: Whether the episode has ended.\n",
        "    \"\"\"\n",
        "    index = self.mem_cntr % self.mem_size  # Circular buffer\n",
        "\n",
        "    # Store the transition in the respective memory arrays\n",
        "    self.state_memory[index] = state\n",
        "    self.new_state_memory[index] = state_\n",
        "    self.action_memory[index] = action\n",
        "    self.reward_memory[index] = reward\n",
        "    self.terminal_memory[index] = done\n",
        "\n",
        "    # Assign the max priority seen so far to new experiences\n",
        "    self.priority_memory[index] = self.max_priority\n",
        "\n",
        "    self.mem_cntr += 1\n",
        "\n",
        "  def sample_buffer(self, batch_size, beta=0.5):\n",
        "    \"\"\"\n",
        "    Sample a batch of transitions from the buffer.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): The size of the batch to sample.\n",
        "        beta (float): The exponent for adjusting the importance-sampling weights.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing states, actions, rewards, next states, terminals, indices of the sampled transitions, and the importance-sampling weights.\n",
        "    \"\"\"\n",
        "    # Determine the range of memory to sample from\n",
        "    num_sampled_elements = min(self.mem_cntr, self.mem_size)\n",
        "    priorities = self.priority_memory[:num_sampled_elements]\n",
        "\n",
        "    # Normalize priorities and convert to probabilities\n",
        "    scaled_priorities = np.power(priorities, self.alpha)\n",
        "    sample_probs = scaled_priorities / np.sum(scaled_priorities)\n",
        "\n",
        "    # Sample experiences based on probabilities\n",
        "    chosen_indices = np.random.choice(num_sampled_elements, batch_size, replace=False, p=sample_probs)\n",
        "\n",
        "    # Retrieve sampled experiences\n",
        "    states = self.state_memory[chosen_indices]\n",
        "    actions = self.action_memory[chosen_indices]\n",
        "    rewards = self.reward_memory[chosen_indices]\n",
        "    states_ = self.new_state_memory[chosen_indices]\n",
        "    terminal = self.terminal_memory[chosen_indices]\n",
        "\n",
        "    # Compute importance-sampling weights and adjust with beta\n",
        "    weights = np.power(self.mem_size * sample_probs[chosen_indices], -beta)\n",
        "    weights /= np.max(weights)  # Normalize for stability\n",
        "    weights = torch.tensor(weights, dtype=torch.float32).view(-1, 1)  # Convert to tensor and reshape\n",
        "\n",
        "    return states, actions, rewards, states_, terminal, chosen_indices, weights\n",
        "\n",
        "  def update_priorities(self, indices, priorities):\n",
        "    \"\"\"\n",
        "    Update the priorities of the sampled transitions in a vectorized manner.\n",
        "\n",
        "    Args:\n",
        "        indices (list or numpy.ndarray): Indices of the sampled transitions.\n",
        "        priorities (list or numpy.ndarray): New priorities for the sampled transitions.\n",
        "    \"\"\"\n",
        "    # Ensure that no priority is set to exactly 0 by using np.maximum, as a priority of 0 would mean a transition is never sampled.\n",
        "    # Adding a small value (1e-5) ensures all priorities are non-zero and transitions have a chance of being sampled.\n",
        "    priorities = np.maximum(priorities, 1e-5)\n",
        "\n",
        "    # Update the priorities in a vectorized manner.\n",
        "    # This is generally faster and more efficient than a loop, especially for large arrays.\n",
        "    self.priority_memory[indices] = priorities\n",
        "\n",
        "    # Update the maximum priority with the largest priority in the new set.\n",
        "    # This value is used to set the priority for new experiences (ensuring they have a high chance of being sampled initially).\n",
        "    self.max_priority = max(self.max_priority, np.max(priorities))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DuelingDeepQNetwork(nn.Module):\n",
        "  def __init__(self, lr, n_actions, name, input_dims, chkpt_dir):\n",
        "    \"\"\"\n",
        "    Initialize the Dueling Deep Q Network.\n",
        "\n",
        "    Args:\n",
        "      lr (float): Learning rate for the optimizer.\n",
        "      n_actions (int): Number of possible actions.\n",
        "      name (str): Name of the network, used in saving and loading models.\n",
        "      input_dims (tuple): Dimensions of the input state.\n",
        "      chkpt_dir (str): Directory where the checkpoints (model weights) are saved.\n",
        "    \"\"\"\n",
        "    super(DuelingDeepQNetwork, self).__init__()\n",
        "    self.chkpt_dir = chkpt_dir\n",
        "    self.checkpoint_file = os.path.join(self.chkpt_dir, name)\n",
        "\n",
        "    # Define the first fully connected layer\n",
        "    self.fc1 = nn.Linear(*input_dims, 128)\n",
        "    # Define the layer for estimating the state-value function V\n",
        "    self.V = nn.Linear(128, 1)\n",
        "    # Define the layer for estimating the advantage function A\n",
        "    self.A = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Set up the optimizer (Adam) and the loss function (Mean Squared Error)\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "    self.loss = nn.MSELoss()\n",
        "    # Define the device (use GPU if available)\n",
        "    self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self, state):\n",
        "    \"\"\"\n",
        "    Perform a forward pass through the network.\n",
        "\n",
        "    Args:\n",
        "      state (torch.Tensor): The input state.\n",
        "\n",
        "    Returns:\n",
        "      V (torch.Tensor): The estimated state-value function.\n",
        "      A (torch.Tensor): The estimated advantage function.\n",
        "    \"\"\"\n",
        "    flat1 = F.relu(self.fc1(state))  # Pass the state through the first fully connected layer\n",
        "    V = self.V(flat1)  # Compute the state-value function\n",
        "    A = self.A(flat1)  # Compute the advantage function\n",
        "\n",
        "    return V, A\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    \"\"\"\n",
        "    Save the model's current state.\n",
        "    \"\"\"\n",
        "    print('...saving checkpoint...')\n",
        "    T.save(self.state_dict(), self.checkpoint_file)\n",
        "\n",
        "  def load_checkpoint(self):\n",
        "    \"\"\"\n",
        "    Load the model's state from a saved checkpoint.\n",
        "    \"\"\"\n",
        "    print('...loading checkpoint...')\n",
        "    self.load_state_dict(T.load(self.checkpoint_file))"
      ],
      "metadata": {
        "id": "SZy3wON4FaDd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self, gamma, epsilon, lr, n_actions, input_dims, mem_size, batch_size, eps_min=0.01, eps_dec=5e-7, replace=1000, beta_start=0.5, beta_increment_per_sampling=0.001, beta_max=1.0, chkpt_dir='tmp/dueling_ddqn'):\n",
        "    \"\"\"\n",
        "    Initialize the agent with given hyperparameters and network parameters.\n",
        "\n",
        "    Args:\n",
        "      gamma (float): discount factor for future rewards.\n",
        "      epsilon (float): initial exploration rate for epsilon-greedy action selection.\n",
        "      lr (float): learning rate for updating the neural network.\n",
        "      n_actions (int): number of possible actions the agent can take.\n",
        "      input_dims (tuple): dimensions of the input features.\n",
        "      mem_size (int): size of the replay memory.\n",
        "      batch_size (int): number of experiences sampled from memory for each learning step.\n",
        "      eps_min (float): minimum value for epsilon (exploration rate).\n",
        "      eps_dec (float): decrement value for epsilon after each episode.\n",
        "      replace (int): number of steps after which the target network weights are updated.\n",
        "      beta_start (float): initial value of beta for importance-sampling weights.\n",
        "      beta_increment_per_sampling (float): increment value for beta after each sampling.\n",
        "      beta_max (float): maximum value for beta.\n",
        "      chkpt_dir (str): directory where model checkpoints are saved.\n",
        "    \"\"\"\n",
        "    # Initialize parameters\n",
        "    self.gamma = gamma\n",
        "    self.epsilon = epsilon\n",
        "    self.lr = lr\n",
        "    self.n_actions = n_actions\n",
        "    self.input_dims = input_dims\n",
        "    self.batch_size = batch_size\n",
        "    self.eps_min = eps_min\n",
        "    self.eps_dec = eps_dec\n",
        "    self.replace_target_cnt = replace\n",
        "    self.beta = beta_start\n",
        "    self.beta_increment_per_sampling = beta_increment_per_sampling\n",
        "    self.beta_max = beta_max\n",
        "    self.chkpt_dir = chkpt_dir\n",
        "    self.learn_step_counter = 0\n",
        "    self.action_space = [i for i in range(self.n_actions)]\n",
        "\n",
        "    # Initialize memory and Dueling DQNs for current and target network\n",
        "    self.memory = PrioritizedReplayBuffer(mem_size, input_dims)\n",
        "    self.q_eval = DuelingDeepQNetwork(lr, n_actions, 'q_eval', input_dims, chkpt_dir)\n",
        "    self.q_next = DuelingDeepQNetwork(lr, n_actions, 'q_next', input_dims, chkpt_dir)\n",
        "\n",
        "    # Initialize variables for averaging network weights\n",
        "    self.average_q_eval_state_dict = None  # To store the averaged state dict of the Q_eval network\n",
        "    self.networks_counter = 0  # To count the number of networks added to the average\n",
        "\n",
        "  def choose_action(self, observation):\n",
        "    \"\"\"\n",
        "    Choose an action based on the current state and the epsilon-greedy policy.\n",
        "\n",
        "    Args:\n",
        "      observation (np.array): the current state observation.\n",
        "\n",
        "    Returns:\n",
        "      action (int): the action chosen by the agent.\n",
        "    \"\"\"\n",
        "    if np.random.random() > self.epsilon:\n",
        "      # Exploitation: choose the best action according to the network's output\n",
        "      state = T.tensor(np.array(observation), dtype=T.float32).to(self.q_eval.device)\n",
        "      _, advantage = self.q_eval.forward(state)\n",
        "      action = T.argmax(advantage).item()\n",
        "    else:\n",
        "      # Exploration: choose a random action\n",
        "      action = np.random.choice(self.action_space)\n",
        "    return action\n",
        "\n",
        "  def store_transition(self, state, action, reward, state_, done):\n",
        "    \"\"\"\n",
        "    Store a transition in the replay buffer.\n",
        "\n",
        "    Args:\n",
        "      state (np.array): the starting state.\n",
        "      action (int): the action taken.\n",
        "      reward (float): the reward received.\n",
        "      state_ (np.array): the next state after taking the action.\n",
        "      done (bool): whether the episode is finished.\n",
        "    \"\"\"\n",
        "    self.memory.store_transition(state, action, reward, state_, done)\n",
        "\n",
        "  def replace_target_network(self):\n",
        "    \"\"\"\n",
        "    Update the target network by copying the weights from the evaluation network.\n",
        "    This happens every 'replace_target_cnt' learning steps.\n",
        "    \"\"\"\n",
        "    if self.learn_step_counter % self.replace_target_cnt == 0:\n",
        "      self.q_next.load_state_dict(self.q_eval.state_dict())\n",
        "\n",
        "  def update_average_network(self, current_state_dict):\n",
        "    \"\"\"\n",
        "    Update the running average of the Q_eval network weights.\n",
        "    This is intended to stabilize the training by smoothing out the variations in the network weights over training steps.\n",
        "\n",
        "    Args:\n",
        "      current_state_dict (dict): state_dict of the current Q_eval network.\n",
        "    \"\"\"\n",
        "    self.networks_counter += 1\n",
        "    if self.average_q_eval_state_dict is None:\n",
        "      self.average_q_eval_state_dict = {k: v.clone().detach() for k, v in current_state_dict.items()}\n",
        "    else:\n",
        "      new_average_q_eval_state_dict = {}\n",
        "      for key in self.average_q_eval_state_dict.keys():\n",
        "        new_average_q_eval_state_dict[key] = (\n",
        "            self.average_q_eval_state_dict[key] * (self.networks_counter - 1)\n",
        "            + current_state_dict[key]\n",
        "        ) / self.networks_counter\n",
        "      self.average_q_eval_state_dict = new_average_q_eval_state_dict\n",
        "\n",
        "  def decrement_epsilon(self):\n",
        "    \"\"\"\n",
        "    Decrement the epsilon value to reduce exploration over time.\n",
        "    \"\"\"\n",
        "    self.epsilon = max(self.epsilon - self.eps_dec, self.eps_min)\n",
        "\n",
        "  def save_models(self):\n",
        "    \"\"\"\n",
        "    Save the current and target network models.\n",
        "    \"\"\"\n",
        "    self.q_eval.save_checkpoint()\n",
        "    self.q_next.save_checkpoint()\n",
        "\n",
        "  def load_models(self):\n",
        "    \"\"\"\n",
        "    Load the saved models for the current and target networks.\n",
        "    \"\"\"\n",
        "    self.q_eval.load_checkpoint()\n",
        "    self.q_next.load_checkpoint()\n",
        "\n",
        "  def learn(self):\n",
        "    \"\"\"\n",
        "    The learning process for the agent. Samples a batch of experiences and updates the network.\n",
        "    \"\"\"\n",
        "    if self.memory.mem_cntr < self.batch_size:\n",
        "      return  # Do not learn until enough samples are available\n",
        "\n",
        "    self.q_eval.optimizer.zero_grad()\n",
        "\n",
        "    # Update the target network and the average network at the specified intervals\n",
        "    if self.learn_step_counter % self.replace_target_cnt == 0:\n",
        "      self.replace_target_network()\n",
        "      self.update_average_network(self.q_eval.state_dict())\n",
        "\n",
        "    # Sample a batch from the replay buffer\n",
        "    states, actions, rewards, states_, dones, indices, weights = self.memory.sample_buffer(self.batch_size, self.beta)\n",
        "\n",
        "    states = T.tensor(states).to(self.q_eval.device)\n",
        "    actions = T.tensor(actions).to(self.q_eval.device)\n",
        "    dones = T.tensor(dones).to(self.q_eval.device)\n",
        "    rewards = T.tensor(rewards).to(self.q_eval.device)\n",
        "    states_ = T.tensor(states_).to(self.q_eval.device)\n",
        "    weights = weights.clone().detach().requires_grad_(True).to(self.q_eval.device)\n",
        "\n",
        "    batch_indices = np.arange(self.batch_size)\n",
        "\n",
        "    # Load the averaged network weights for predicting the next Q-values\n",
        "    self.q_eval.load_state_dict(self.average_q_eval_state_dict)\n",
        "\n",
        "    V_s, A_s = self.q_eval.forward(states)\n",
        "    V_s_avg, A_s_avg = self.q_eval.forward(states_)\n",
        "\n",
        "    q_pred = T.add(V_s, (A_s - A_s.mean(dim=1, keepdim=True)))[batch_indices, actions]\n",
        "    q_next = T.add(V_s_avg, (A_s_avg - A_s_avg.mean(dim=1, keepdim=True)))\n",
        "    q_next[dones.bool()] = 0.0  # Set Q value of next state to 0 if the episode ended\n",
        "    q_target = rewards + self.gamma * q_next[batch_indices, T.argmax(A_s_avg, dim=1)]\n",
        "\n",
        "    # Compute loss, perform backpropagation, and update network weights\n",
        "    loss = self.q_eval.loss(q_target, q_pred) * weights  # Apply importance-sampling weights\n",
        "    loss = loss.mean()  # Average the loss over the batch\n",
        "    loss.backward()\n",
        "    self.q_eval.optimizer.step()\n",
        "\n",
        "    # Update learning step counter and epsilon\n",
        "    self.learn_step_counter += 1\n",
        "    self.decrement_epsilon()\n",
        "\n",
        "    # Increment beta, ensuring it doesn't exceed beta_max\n",
        "    self.beta = min(self.beta + self.beta_increment_per_sampling, self.beta_max)\n",
        "\n",
        "    # Update the priorities in the replay buffer based on TD error\n",
        "    td_errors = (q_target - q_pred).detach().cpu().numpy()\n",
        "    new_priorities = np.abs(td_errors) + 1e-5  # Ensure priorities are non-zero\n",
        "    self.memory.update_priorities(indices, new_priorities)\n"
      ],
      "metadata": {
        "id": "4vR3ULfSSJZl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcStandard:\n",
        "  def __init__(self, sentence, tree):\n",
        "    self.gold_tree = tree\n",
        "    self.sentence = sentence\n",
        "    self.buffer = [i for i in range(len(self.sentence))]\n",
        "    self.stack = []\n",
        "    self.arcs = [-1 for _ in range(len(self.sentence))]\n",
        "    self.prev_actions = [None, None, None, None, None]\n",
        "\n",
        "    # three shift moves to initialize the stack\n",
        "    self.shift()\n",
        "    self.shift()\n",
        "    if len(self.sentence) > 2:\n",
        "      self.shift()\n",
        "\n",
        "    self.loss = [0 for i in range(len(self.stack))]\n",
        "\n",
        "  def shift(self):\n",
        "    b1 = self.buffer[0]\n",
        "    self.buffer = self.buffer[1:]\n",
        "    self.stack.append(b1)\n",
        "    if len(self.prev_actions) == 5:\n",
        "      self.prev_actions.pop(0)\n",
        "    self.prev_actions.append('shift')\n",
        "\n",
        "  def left_arc(self):\n",
        "    o1 = self.stack.pop()\n",
        "    o2 = self.stack.pop()\n",
        "    self.arcs[o2] = o1\n",
        "    self.stack.append(o1)\n",
        "    if len(self.prev_actions) == 5:\n",
        "      self.prev_actions.pop(0)\n",
        "    self.prev_actions.append('left_arc')\n",
        "    if len(self.stack) < 2 and len(self.buffer) > 0:\n",
        "      self.shift()\n",
        "      if len(self.prev_actions) == 5:\n",
        "        self.prev_actions.pop(0)\n",
        "      self.prev_actions.append('shift')\n",
        "\n",
        "  def right_arc(self):\n",
        "    o1 = self.stack.pop()\n",
        "    o2 = self.stack.pop()\n",
        "    self.arcs[o1] = o2\n",
        "    self.stack.append(o2)\n",
        "    if len(self.prev_actions) == 5:\n",
        "      self.prev_actions.pop(0)\n",
        "    self.prev_actions.append('right_arc')\n",
        "    if len(self.stack) < 2 and len(self.buffer) > 0:\n",
        "      self.shift()\n",
        "      if len(self.prev_actions) == 5:\n",
        "        self.prev_actions.pop(0)\n",
        "      self.prev_actions.append('shift')\n",
        "\n",
        "  def is_tree_final(self):\n",
        "    return len(self.stack) == 1 and len(self.buffer) == 0\n",
        "\n",
        "  def print_configuration(self):\n",
        "    s = [self.sentence[i] for i in self.stack]\n",
        "    b = [self.sentence[i] for i in self.buffer]\n",
        "    print(s, b)\n",
        "    print(self.arcs)\n",
        "\n",
        "  def get_valid_actions(self):\n",
        "    \"\"\"\n",
        "    Determine the valid actions that can be taken from the current state of the parser.\n",
        "\n",
        "    Returns:\n",
        "      list: A list of valid actions.\n",
        "    \"\"\"\n",
        "    valid_actions = ['shift', 'left_arc', 'right_arc']\n",
        "\n",
        "    # 'shift' is not valid if the buffer is empty\n",
        "    if len(self.buffer) == 0:\n",
        "      valid_actions.remove('shift')\n",
        "\n",
        "    # 'left_arc' is not valid if:\n",
        "    # 1. The stack has less than 2 elements\n",
        "    # 2. The stack has exactly 2 elements but the buffer is not empty\n",
        "    # 3. The second-to-last element on the stack is the root (0)\n",
        "    if len(self.stack) < 2 or (len(self.stack) == 2 and len(self.buffer) != 0) or self.stack[-2] == 0:\n",
        "      valid_actions.remove('left_arc')\n",
        "\n",
        "    # 'right_arc' is not valid if:\n",
        "    # 1. The stack has less than 2 elements\n",
        "    # 2. The second-to-last element on the stack is the root (0) and the buffer is not empty\n",
        "    if len(self.stack) < 2 or (self.stack[-2] == 0 and len(self.buffer) != 0):\n",
        "      valid_actions.remove('right_arc')\n",
        "\n",
        "    return valid_actions\n",
        "\n",
        "  def get_binary_features(self, N=10):\n",
        "    \"\"\"\n",
        "    Construct the binary feature vector for the current state.\n",
        "    Each of the top 10 tokens from the stack and the first 10 tokens from the buffer\n",
        "    will have their gold head position binary encoded using 5 bits, and additional bits\n",
        "    indicating if the gold head is lost and if all dependents are already collected.\n",
        "\n",
        "    Args:\n",
        "      N (int): The number of tokens from the stack and buffer to consider.\n",
        "\n",
        "    Returns:\n",
        "      np.array: The binary feature vector representing the current state.\n",
        "    \"\"\"\n",
        "    # Initialize the binary feature vector\n",
        "    binary_features = []\n",
        "\n",
        "    # Get the top N tokens from the stack and the first N tokens from the buffer\n",
        "    stack_elements = self.stack[-N:] if len(self.stack) >= N else self.stack + [-1] * (N - len(self.stack))\n",
        "    buffer_elements = self.buffer[:N] if len(self.buffer) >= N else self.buffer + [-1] * (N - len(self.buffer))\n",
        "\n",
        "    # Combine stack and buffer elements for easier indexing\n",
        "    combined_elements = stack_elements + buffer_elements\n",
        "\n",
        "    # Get the complete stack and buffer for checking if the gold head is lost\n",
        "    complete_elements = self.stack + self.buffer\n",
        "\n",
        "    # Encode the position of the gold head for each element in stack_elements and buffer_elements\n",
        "    for token_index in combined_elements:\n",
        "      if token_index == -1:\n",
        "        binary_features.extend([-1, -1, -1, -1, -1, -1, -1])  # Padding representation with 7 bits\n",
        "      else:\n",
        "        if token_index == 0:\n",
        "          binary_features.extend([1, 1, 1, 1, 1, 0] + [self.has_collected_all_dependents(token_index)])\n",
        "        else:\n",
        "          gold_head = self.gold_tree[token_index]\n",
        "          gold_head_pos = combined_elements.index(gold_head) if gold_head in combined_elements else -1\n",
        "          gold_head_lost = 1 if (self.gold_tree[token_index] not in complete_elements and token_index != 0) else 0\n",
        "          all_dependents_collected = self.has_collected_all_dependents(token_index)\n",
        "          if gold_head_pos == -1:\n",
        "            binary_features.extend([-1, -1, -1, -1, -1, gold_head_lost, all_dependents_collected])  # Gold head is lost or not in the 20 elements\n",
        "          else:\n",
        "            binary_features.extend([int(bit) for bit in self.position_to_binary(gold_head_pos)] + [gold_head_lost, all_dependents_collected])\n",
        "    # Encode the last 5 (or fewer, with padding) actions leading to this state\n",
        "    binary_features.extend(self.get_padded_prev_actions(self.prev_actions))\n",
        "\n",
        "    # Encode all valid actions in this state\n",
        "    # Assuming 'get_valid_actions' returns a list of valid actions in the current state\n",
        "    valid_actions = self.get_valid_actions()\n",
        "    binary_features.extend([1 if action in valid_actions else 0 for action in ['shift', 'left_arc', 'right_arc']])\n",
        "\n",
        "    return np.array(binary_features)\n",
        "\n",
        "  def position_to_binary(self, pos, max_pos=20):\n",
        "    \"\"\"\n",
        "    Convert a position to a 5-bit binary representation.\n",
        "    If the position is out of range (lost or not among the 20 elements), return '00000'.\n",
        "\n",
        "    Args:\n",
        "        pos (int): The position to be converted.\n",
        "        max_pos (int): The maximum position value (20 for top 10 in stack and first 10 in buffer).\n",
        "\n",
        "    Returns:\n",
        "        str: A 5-bit binary string representing the position.\n",
        "    \"\"\"\n",
        "    if pos < 0 or pos >= max_pos:\n",
        "        return '00000'\n",
        "    return format(pos, '05b')\n",
        "\n",
        "  def has_collected_all_dependents(self, first_common_parent):\n",
        "    for token in self.stack:\n",
        "      if self.gold_tree[token] == first_common_parent:\n",
        "        return 0\n",
        "\n",
        "    for token in self.buffer:\n",
        "      if self.gold_tree[token] == first_common_parent:\n",
        "        return 0\n",
        "\n",
        "    return 1\n",
        "\n",
        "  def action_to_binary(self, action):\n",
        "    \"\"\"\n",
        "    Convert an action to its binary (one-hot encoded) representation.\n",
        "\n",
        "    Args:\n",
        "      action (str): The action to be converted.\n",
        "\n",
        "    Returns:\n",
        "      list: The binary representation of the action.\n",
        "    \"\"\"\n",
        "    if action == 'left_arc':\n",
        "      return [1, 0]\n",
        "    elif action == 'right_arc':\n",
        "      return [0, 1]\n",
        "    elif action == 'shift':\n",
        "      return [1, 1]\n",
        "    else:  # For padding or unknown actions\n",
        "      return [0, 0]\n",
        "\n",
        "  def get_padded_prev_actions(self, prev_actions, max_prev_actions=5):\n",
        "    \"\"\"\n",
        "    Get the binary representations of previous actions, padded with zeros if there are fewer than 'max_prev_actions'.\n",
        "\n",
        "    Args:\n",
        "      prev_actions (list): The list of the last few actions taken.\n",
        "      max_prev_actions (int): The maximum number of previous actions to consider.\n",
        "\n",
        "    Returns:\n",
        "      list: A flattened list containing the binary representations of previous actions, padded with zeros.\n",
        "    \"\"\"\n",
        "    # Convert each previous action to its binary representation\n",
        "    binary_prev_actions = [self.action_to_binary(action) for action in prev_actions]\n",
        "\n",
        "    # Calculate the number of actions to pad\n",
        "    num_padding = max_prev_actions - len(binary_prev_actions)\n",
        "\n",
        "    # Pad with vectors representing 'no action'\n",
        "    binary_prev_actions.extend([self.action_to_binary(None)] * num_padding)\n",
        "\n",
        "    # Flatten the list of binary vectors into a single list\n",
        "    return [bit for action_bits in binary_prev_actions for bit in action_bits]\n"
      ],
      "metadata": {
        "id": "31qzVY3AhJca"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DependencyParsingEnv(gym.Env):\n",
        "  metadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self, sentence, tree, max_steps_per_episode=5):\n",
        "    super(DependencyParsingEnv, self).__init__()\n",
        "    self.sentence = sentence\n",
        "    self.tree = tree\n",
        "    self.parser = ArcStandard(sentence, tree)\n",
        "    self.previous_action = [-1, 0]\n",
        "    self.positive_reward = 100\n",
        "    self.current_step = 0\n",
        "    self.max_steps_per_episode = max_steps_per_episode\n",
        "\n",
        "    # Define action and observation space\n",
        "    self.action_space = spaces.Discrete(3)\n",
        "    self.observation_space = spaces.Box(low=-1, high=1, shape=(self.parser.get_binary_features().shape[0],), dtype=np.float32)\n",
        "\n",
        "  def get_valid_actions(self):\n",
        "    valid_actions = self.parser.get_valid_actions()\n",
        "    valid_actions_indexes = []\n",
        "    if 'left_arc' in valid_actions:\n",
        "      valid_actions_indexes.append(0)\n",
        "    if 'right_arc' in valid_actions:\n",
        "      valid_actions_indexes.append(1)\n",
        "    if 'shift' in valid_actions:\n",
        "      valid_actions_indexes.append(2)\n",
        "\n",
        "    return valid_actions_indexes\n",
        "\n",
        "  def step(self, action):\n",
        "    self.current_step += 1\n",
        "    valid_actions = self.get_valid_actions()\n",
        "    # Map the action to the parser's functions\n",
        "    if action == 0 and action in valid_actions:  # left_arc\n",
        "      self.parser.left_arc()\n",
        "    elif action == 1 and action in valid_actions:  # right_arc\n",
        "      self.parser.right_arc()\n",
        "    elif action == 2 and action in valid_actions:  # shift\n",
        "      self.parser.shift()\n",
        "\n",
        "    # Compute the reward for the current action\n",
        "    reward, _ = self.computeReward(self.parser.stack, self.parser.buffer, self.parser.gold_tree, action, self.previous_action)\n",
        "\n",
        "    # Update the previous action\n",
        "    self.previous_action = [action, reward]\n",
        "\n",
        "    # Check if the episode (parsing of one sentence) is done\n",
        "    done = self.parser.is_tree_final()\n",
        "\n",
        "    # Check if max steps per episode is reached\n",
        "    truncated = False\n",
        "    if self.current_step >= self.max_steps_per_episode:\n",
        "      done = True\n",
        "      truncated = True\n",
        "\n",
        "    # Get the next state representation\n",
        "    state = self.parser.get_binary_features().astype(np.float32)\n",
        "\n",
        "    # Additional info can be added if necessary\n",
        "    info = {}\n",
        "\n",
        "    return state, reward, done, truncated, info\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    # Reset the state of the environment to an initial state\n",
        "    self.parser = ArcStandard(self.sentence, self.tree)\n",
        "    self.previous_action = [-1, 0]\n",
        "    self.current_step = 0\n",
        "    observation = self.parser.get_binary_features().astype(np.float32)\n",
        "    info = {}  # Optional: can contain additional information\n",
        "    return observation, info\n",
        "\n",
        "  def render(self, mode='human', close=False):\n",
        "    # Render the environment to the screen\n",
        "    self.parser.print_configuration()\n",
        "\n",
        "  def computeSimpleReward(self, stack, buffer, gold_tree, action, previous_action):\n",
        "    # LEFT_ARC\n",
        "    if action == 0:\n",
        "      if len(stack) < 2 or (len(stack) == 2 and len(buffer) != 0) or stack[-2] == 0:\n",
        "        return -100, False\n",
        "      reward = 0\n",
        "      s1 = stack[-1]\n",
        "      s2 = stack[-2]\n",
        "\n",
        "      if gold_tree[s2] == s1:\n",
        "        reward += 2\n",
        "\n",
        "      for i in stack:\n",
        "        if gold_tree[i] == s2 or gold_tree[s2] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      for i in buffer:\n",
        "        if gold_tree[i] == s2 or gold_tree[s2] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      return reward, False\n",
        "    # RIGHT_ARC\n",
        "    elif action == 1:\n",
        "      if len(stack) < 2 or (stack[-2] == 0 and len(buffer) > 0):\n",
        "        return -100, False\n",
        "      reward = 0\n",
        "\n",
        "      s1 = stack[-1]\n",
        "      s2 = stack[-2]\n",
        "\n",
        "      if gold_tree[s1] == s2:\n",
        "        reward += 2\n",
        "\n",
        "      for i in stack:\n",
        "        if gold_tree[i] == s1 or gold_tree[s1] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      for i in buffer:\n",
        "        if gold_tree[i] == s1 or gold_tree[s1] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      return reward, False\n",
        "    # SHIFT\n",
        "    elif action == 2:\n",
        "      if len(buffer) == 0:\n",
        "        return -100, False\n",
        "\n",
        "      return 0, False\n",
        "\n",
        "  def computeReward(self, stack, buffer, gold_tree, action, previous_action):\n",
        "    # LEFT_ARC\n",
        "    if action == 0:\n",
        "      if len(stack) < 2 or (len(stack) == 2 and len(buffer) != 0) or stack[-2] == 0:\n",
        "        return -100, False\n",
        "      reward = 0\n",
        "      s1 = stack[-1]\n",
        "      s2 = stack[-2]\n",
        "\n",
        "      if gold_tree[s2] == s1:\n",
        "        reward += 2\n",
        "\n",
        "      for i in stack:\n",
        "        if gold_tree[i] == s2 or gold_tree[s2] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      for i in buffer:\n",
        "        if gold_tree[i] == s2 or gold_tree[s2] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      if previous_action[0] == 2:\n",
        "        reward -= previous_action[1]\n",
        "\n",
        "      if reward == 1:\n",
        "        reward = self.positive_reward\n",
        "\n",
        "      return reward, False\n",
        "    # RIGHT_ARC\n",
        "    elif action == 1:\n",
        "      if len(stack) < 2 or (stack[-2] == 0 and len(buffer) > 0):\n",
        "        return -100, False\n",
        "      reward = 0\n",
        "\n",
        "      s1 = stack[-1]\n",
        "      s2 = stack[-2]\n",
        "\n",
        "      if gold_tree[s1] == s2:\n",
        "        reward += 2\n",
        "\n",
        "      for i in stack:\n",
        "        if gold_tree[i] == s1 or gold_tree[s1] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      for i in buffer:\n",
        "        if gold_tree[i] == s1 or gold_tree[s1] == i:\n",
        "          reward -= 1\n",
        "\n",
        "      if previous_action[0] == 2:\n",
        "        reward -= previous_action[1]\n",
        "\n",
        "      if reward == 1:\n",
        "        reward = self.positive_reward\n",
        "\n",
        "      return reward, False\n",
        "    # SHIFT\n",
        "    elif action == 2:\n",
        "      if len(buffer) == 0:\n",
        "        return -100, False\n",
        "\n",
        "      reward = 0\n",
        "      s1 = stack[-1]\n",
        "\n",
        "      for i in buffer:\n",
        "        if gold_tree[i] == s1:\n",
        "          return self.positive_reward, False # a right child allows a costless shift\n",
        "\n",
        "      # s1 is a right child without right children\n",
        "      if gold_tree[s1] < s1:\n",
        "        b1 = buffer[0]\n",
        "        sacrifice = 0\n",
        "        # search for a lost father so that we can create an arc between s1 and the orphan node\n",
        "        orphan = False\n",
        "        father = gold_tree[b1]\n",
        "        #print(b1, \" \", father)\n",
        "        while not orphan and father != 0:\n",
        "          #print(\"QUA\")\n",
        "          flag = father in stack\n",
        "          #print(\"flag: \", flag)\n",
        "          if (father not in buffer and not flag):\n",
        "            orphan = True\n",
        "          if flag:\n",
        "            #print(\"father in stack\", father, )\n",
        "            return -1, False\n",
        "          #print(\"orphan: \", orphan)\n",
        "          father = gold_tree[father]\n",
        "\n",
        "        if orphan:\n",
        "          #print(\"orphan\")\n",
        "          return 0, False\n",
        "\n",
        "        for i in stack:\n",
        "          if gold_tree[i] == b1 or gold_tree[b1] == i:\n",
        "            sacrifice -= 1\n",
        "        for i in buffer:\n",
        "          if gold_tree[i] == b1 or gold_tree[b1] == i:\n",
        "            sacrifice -= 1\n",
        "\n",
        "        for i in stack:\n",
        "          if gold_tree[i] == s1 or gold_tree[s1] == i:\n",
        "            reward -= 1\n",
        "\n",
        "        if reward == 0:\n",
        "          return self.positive_reward, False\n",
        "\n",
        "        return max(reward, sacrifice), False\n",
        "\n",
        "      # s1 is a left child with no right children\n",
        "      for i in stack:\n",
        "        if gold_tree[i] == s1:\n",
        "          reward -= 1\n",
        "\n",
        "      if reward == 0:\n",
        "        reward = self.positive_reward\n",
        "      return reward, False"
      ],
      "metadata": {
        "id": "tdMmroZ1GUpl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['<ROOT>', 'Hello', 'World', '!']\n",
        "gold_tree = [-1, 0, 1, 1]\n",
        "\n",
        "env = DependencyParsingEnv(sentence, gold_tree)\n",
        "# If the environment don't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ],
      "metadata": {
        "id": "uIAPNC_015dF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(gold, preds):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for g, p in zip(gold, preds):\n",
        "    for i in range(1,len(g)):\n",
        "      total += 1\n",
        "      if g[i] == p[i]:\n",
        "        correct += 1\n",
        "\n",
        "  return correct/total"
      ],
      "metadata": {
        "id": "vY1SwhNqE4LM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 200\n",
        "LSTM_SIZE = 200\n",
        "LSTM_LAYERS = 2\n",
        "MLP_SIZE = 200\n",
        "DROPOUT = 0.2\n",
        "EPOCHS = 15\n",
        "LR = 0.001   # learning rate\n",
        "PROBABILITY_THRESHOLD = 0.1"
      ],
      "metadata": {
        "id": "2tOBZU9oFAaO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BilstmParser(nn.Module):\n",
        "\n",
        "  def __init__(self, device):\n",
        "    super(BilstmParser, self).__init__()\n",
        "    self.device = device\n",
        "    self.embeddings = nn.Embedding(len(emb_dictionary), EMBEDDING_SIZE, padding_idx=emb_dictionary[\"<pad>\"])\n",
        "\n",
        "    # initialize bi-LSTM\n",
        "    self.lstm = nn.LSTM(EMBEDDING_SIZE, LSTM_SIZE, num_layers = LSTM_LAYERS, bidirectional=True, dropout=DROPOUT)\n",
        "\n",
        "    # initialize feedforward\n",
        "    self.w1 = torch.nn.Linear(8*LSTM_SIZE, MLP_SIZE, bias=True)\n",
        "    self.activation = torch.nn.Tanh()\n",
        "    self.w2 = torch.nn.Linear(MLP_SIZE, 3, bias=True)\n",
        "    self.softmax = torch.nn.Softmax(dim=-1)\n",
        "\n",
        "    self.dropout = torch.nn.Dropout(DROPOUT)\n",
        "\n",
        "    #self.x = []\n",
        "    self.h = torch.zeros(1,1,1)\n",
        "\n",
        "  def forward(self, x, paths, flag_enc, flag_feat):\n",
        "    if flag_enc:\n",
        "      # get the embeddings\n",
        "      x = [self.dropout(self.embeddings(torch.tensor(i).to(self.device))) for i in x]\n",
        "      #if flag_feat:\n",
        "      # run the bi-lstm\n",
        "      self.h = self.lstm_pass(x) # size(longest_sentence, batch_size, features)\n",
        "\n",
        "    # for each parser configuration that we need to score we arrange from the\n",
        "    # output of the bi-lstm the correct input for the feedforward\n",
        "    mlp_input = self.get_mlp_input(paths, self.h)\n",
        "\n",
        "    # run the feedforward and get the scores for each possible action\n",
        "    out = self.mlp(mlp_input)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def lstm_pass(self, x):\n",
        "    x = torch.nn.utils.rnn.pack_sequence(x, enforce_sorted=False)\n",
        "    h, (h_0, c_0) = self.lstm(x)\n",
        "    h, h_sizes = torch.nn.utils.rnn.pad_packed_sequence(h) # size h: (length_sentences, batch, output_hidden_units)\n",
        "    return h\n",
        "\n",
        "  def get_mlp_input(self, configurations, h):\n",
        "    mlp_input = []\n",
        "    zero_tensor = torch.zeros(2*LSTM_SIZE, requires_grad=False).to(self.device)\n",
        "    for i in range(len(configurations)): # for every sentence in the batch\n",
        "      mlp_input.append(torch.cat([zero_tensor if configurations[i][0] == -1 else h[configurations[i][0]][i], zero_tensor if configurations[i][1] == -1 else h[configurations[i][1]][i], zero_tensor if configurations[i][2]==-1 else h[configurations[i][2]][i], zero_tensor if configurations[i][3] == -1 else h[configurations[i][3]][i]]))\n",
        "    mlp_input = torch.stack(mlp_input).to(self.device)\n",
        "    return mlp_input\n",
        "\n",
        "  def mlp(self, x):\n",
        "    return self.softmax(self.w2(self.dropout(self.activation(self.w1(self.dropout(x))))))\n",
        "\n",
        "  # we use this function at inference time. We run the parser and at each step\n",
        "  # we pick as next move the one with the highest score assigned by the model\n",
        "  def infere(self, x):\n",
        "\n",
        "    parsers = [ArcStandard(i) for i in x]\n",
        "\n",
        "    x = [self.embeddings(torch.tensor(i).to(self.device)) for i in x]\n",
        "\n",
        "    h = self.lstm_pass(x)\n",
        "\n",
        "    while not self.parsed_all(parsers):\n",
        "      # get the current configuration and score next moves\n",
        "      configurations = self.get_configurations(parsers)\n",
        "      mlp_input = self.get_mlp_input(configurations, h)\n",
        "      mlp_out = self.mlp(mlp_input)\n",
        "      # take the next parsing step\n",
        "      self.parse_step(parsers, mlp_out)\n",
        "\n",
        "    # return the predicted dependency tree\n",
        "    return [parser.arcs for parser in parsers]\n",
        "\n",
        "  def get_configurations(self, parsers):\n",
        "    configurations = []\n",
        "\n",
        "    for parser in parsers:\n",
        "      if parser.is_tree_final():\n",
        "        conf = [-1, -1, -1, -1]\n",
        "      else:\n",
        "        if len(parser.stack) == 0:\n",
        "          conf = [-1, -1, -1]\n",
        "        elif len(parser.stack) == 1:\n",
        "          conf = [-1, -1, parser.stack[-1]]\n",
        "        elif len(parser.stack) == 2:\n",
        "          conf = [-1, parser.stack[-2], parser.stack[-1]]\n",
        "        else:\n",
        "          conf = [parser.stack[-3], parser.stack[-2], parser.stack[-1]]\n",
        "        if len(parser.buffer) == 0:\n",
        "          conf.append(-1)\n",
        "        else:\n",
        "          conf.append(parser.buffer[0])\n",
        "      configurations.append(conf)\n",
        "\n",
        "    return configurations\n",
        "\n",
        "  def parsed_all(self, parsers):\n",
        "    for parser in parsers:\n",
        "      if not parser.is_tree_final():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  # in this function we select and perform the next move according to the scores obtained.\n",
        "  def parse_step(self, parsers, moves):\n",
        "    moves_argm = moves.argmax(-1)\n",
        "    for i in range(len(parsers)):\n",
        "      if parsers[i].is_tree_final():\n",
        "        continue\n",
        "      else:\n",
        "        if moves_argm[i] == 0:\n",
        "          if parsers[i].stack[-2] != 0:\n",
        "            parsers[i].left_arc()\n",
        "          else:\n",
        "            if len(parsers[i].buffer) > 0:\n",
        "              parsers[i].shift()\n",
        "            else:\n",
        "              parsers[i].right_arc()\n",
        "        elif moves_argm[i] == 1:\n",
        "          if parsers[i].stack[-2] == 0 and len(parsers[i].buffer)>0:\n",
        "            parsers[i].shift()\n",
        "          else:\n",
        "            parsers[i].right_arc()\n",
        "        elif moves_argm[i] == 2:\n",
        "          if len(parsers[i].buffer) > 0:\n",
        "            parsers[i].shift()\n",
        "          else:\n",
        "            if moves[i][0] > moves[i][1]:\n",
        "              if parsers[i].stack[-2] != 0:\n",
        "                parsers[i].left_arc()\n",
        "              else:\n",
        "                parsers[i].right_arc()\n",
        "            else:\n",
        "              parsers[i].right_arc()"
      ],
      "metadata": {
        "id": "K3-BaZsZFDjn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_min_indices(nums):\n",
        "  min_value = min(nums)\n",
        "  min_indices = [i for i, num in enumerate(nums) if num == min_value]\n",
        "  return min_indices\n",
        "\n",
        "def execute(parsers, actions, oracles, costs):\n",
        "  for parser, action, oracle, cost in zip(parsers, actions, oracles, costs):\n",
        "    if parser.is_tree_final():\n",
        "      continue\n",
        "    else:\n",
        "      if action == 0:\n",
        "        parser.left_arc()\n",
        "        oracle.previous_action = [0, cost[0]]\n",
        "      elif action == 1:\n",
        "        parser.right_arc()\n",
        "        oracle.previous_action = [1, cost[1]]\n",
        "      elif action == 2:\n",
        "        parser.shift()\n",
        "        oracle.previous_action = [2, cost[2]]\n",
        "\n",
        "def choose_next_amb(iteration, transition, min_cost):\n",
        "  if transition in min_cost:\n",
        "    return transition\n",
        "  else:\n",
        "    return min_cost[rd.randint(0, len(min_cost) - 1)]\n",
        "\n",
        "def choose_next_exp(iteration, transition, min_cost):\n",
        "  if iteration >= 1 and rd.random() > PROBABILITY_THRESHOLD:\n",
        "    return transition\n",
        "  else:\n",
        "    return choose_next_amb(iteration, transition, min_cost)\n",
        "\n",
        "def parsed_all(parsers):\n",
        "  for parser in parsers:\n",
        "    if not parser.is_tree_final():\n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "UGrDX7-hFXgG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, optimizer, epoch, device):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  count = 0\n",
        "  error_count = 0\n",
        "\n",
        "  # For each batch\n",
        "  for batch in dataloader:\n",
        "    # Extract sentence enconding, sentence itself and gold tree for each sentence in the batch\n",
        "    enc_sentences, sentences, trees = batch\n",
        "    # Reset the gradient for the current batch\n",
        "    optimizer.zero_grad()\n",
        "    # Containers to store transitions scores and respective gold labels\n",
        "    global_transitions_scores = []\n",
        "    global_gold_transitions = []\n",
        "\n",
        "    # Flag to tell the model whether to save the encodings and the features tensor h for a new batch or not\n",
        "    flag_enc = True\n",
        "    flag_feat = True\n",
        "    # Initialize a parser and an oracle for each sentence in the batch\n",
        "    parsers = [ArcStandard(s) for s in sentences]\n",
        "\n",
        "    # While each sentence hasn't been fully parsed\n",
        "    while not parsed_all(parsers):\n",
        "\n",
        "      # Save configuration: later we'll need the sequence of configurations in order to associate each one to the correct transition\n",
        "      configurations = []\n",
        "      for parser in parsers:\n",
        "        if parser.is_tree_final():\n",
        "          configurations.append([-1, -1, -1, -1])\n",
        "        else:\n",
        "          if len(parser.stack) == 0:\n",
        "            configurations.append([-1, -1, -1])\n",
        "          elif len(parser.stack) == 1:\n",
        "            configurations.append([-1, -1, parser.stack[-1]])\n",
        "          elif len(parser.stack) == 2:\n",
        "            configurations.append([-1, parser.stack[-2], parser.stack[-1]])\n",
        "          else:\n",
        "            configurations.append([parser.stack[-3], parser.stack[-2], parser.stack[-1]])\n",
        "          if len(parser.buffer) == 0:\n",
        "            configurations[-1].append(-1)\n",
        "          else:\n",
        "            configurations[-1].append(parser.buffer[0])\n",
        "\n",
        "      # The model produce the scores for each transition given the current configuration\n",
        "      transitions_scores_tensor = model(enc_sentences, configurations, flag_enc, flag_feat)\n",
        "      transitions_scores = transitions_scores_tensor.cpu().detach().numpy()\n",
        "      flag_enc = False\n",
        "      flag_feat = False\n",
        "\n",
        "      # Cost of each transition for each current configuration\n",
        "      costs = [oracle.provideTransitionCosts() for oracle in oracles]\n",
        "\n",
        "      # Legal transitions for each current configuration\n",
        "      legal_moves = [[index for index, value in enumerate(cost) if value != float('inf')] for cost in costs]\n",
        "\n",
        "      # Legal transition with higher score according to the model for each current configuration\n",
        "      predicted_transition = [moves[np.argmax([scores[i] for i in moves])] if not parser.is_tree_final() else -1 for scores, moves, parser in zip(transitions_scores, legal_moves, parsers)]\n",
        "\n",
        "      # Collect the set of transitions with minimum cost for each current configuration\n",
        "      min_cost_transitions = [find_min_indices(cost) for cost in costs]\n",
        "\n",
        "      # Collect the best scoring transition among the ones with minimum cost for each current configuration\n",
        "      best_min_cost_transitions = [\n",
        "        max(\n",
        "        (score, i) for i, score in enumerate(scoring_quadruplet) if i in min_cost_transition\n",
        "        )[1]\n",
        "        for scoring_quadruplet, min_cost_transition in zip(transitions_scores, min_cost_transitions)\n",
        "      ]\n",
        "\n",
        "      # Select a transition: the one predicted by the model or a randomly chosen one from the set of minimum cost transitions\n",
        "      actual_transitions = [choose_next_exp(epoch, predicted_transition[i], min_cost_transitions[i]) for i in range(len(predicted_transition))]\n",
        "\n",
        "      # Check if the predicted transition is among the ones with minimum cost: if not we need to update the model\n",
        "      for i, parser in enumerate(parsers):\n",
        "        if not parser.is_tree_final():# and predicted_transition[i] not in min_cost_transitions[i]:\n",
        "          global_transitions_scores.append(transitions_scores_tensor[i])\n",
        "          global_gold_transitions.append(best_min_cost_transitions[i])\n",
        "\n",
        "      # Perform the decided transition\n",
        "      execute(parsers, actual_transitions, oracles, costs)\n",
        "      #executeExatDynamicOracle(actual_transitions, parsers, trees)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    count +=1\n",
        "\n",
        "  return total_loss/count"
      ],
      "metadata": {
        "id": "8A4pLF5SFhr9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateSingleTree(gold, preds):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for i in range(1,len(gold)):\n",
        "    total += 1\n",
        "    if gold[i] == preds[i]:\n",
        "      correct += 1\n",
        "\n",
        "  return correct/total"
      ],
      "metadata": {
        "id": "QAhdX54NF4jI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX --no-cache-dir\n",
        "!pip install tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FViOElzfRpBN",
        "outputId": "64e227e3-e55d-4d02-fbbb-bdcd036d8002"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_forked_episodes = 5\n",
        "max_episode_length = 100\n",
        "max_epochs= 15\n",
        "#torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "agent = Agent(gamma=0.9, epsilon=1.0, lr=5e-4, n_actions=3, input_dims=[153], mem_size=50000, batch_size=1000, eps_min=0.01, eps_dec=1e-7, replace=100)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "  counter = 0\n",
        "  tot_reward = 0\n",
        "  tot_epsilon = 0\n",
        "  for batch_data in bilstm_train_dataloader:\n",
        "    enc_sentences, sentences, trees = batch_data\n",
        "    for enc_sentence, sentence, tree in zip(enc_sentences, sentences, trees):\n",
        "      for _ in range(max_forked_episodes):\n",
        "        env = DependencyParsingEnv(sentence, tree, max_steps_per_episode=max_episode_length)\n",
        "        state = env.reset()[0]\n",
        "        for _ in range(max_episode_length):\n",
        "          action = agent.choose_action(state)\n",
        "          valid_actions = env.get_valid_actions()\n",
        "          if np.random.rand() < 0.05 and len(valid_actions) != 0:  # Forking probability\n",
        "            action = np.random.choice(valid_actions)\n",
        "          next_state, reward, done, truncated, _ = env.step(action)\n",
        "          agent.store_transition(state, action, reward, next_state, done)\n",
        "          #print(\"Epsilon \", agent.epsilon)\n",
        "          #print(\"Reward \", reward)\n",
        "          counter += 1\n",
        "          tot_epsilon += agent.epsilon\n",
        "          tot_reward += reward\n",
        "          agent.learn()\n",
        "          state = next_state\n",
        "          if done or truncated:\n",
        "            break\n",
        "        if done:\n",
        "          break  # No more forking if the true end of the sentence is reached\n",
        "  writer.add_scalar('epsilon', tot_epsilon / counter, epoch)\n",
        "  print(tot_epsilon / counter)\n",
        "  writer.add_scalar('reward', tot_reward / counter, epoch)\n",
        "  print(tot_reward / counter)\n",
        "\n",
        "  count = 0\n",
        "  tot_loss = 0\n",
        "  for batch_data in bilstm_train_dataloader:\n",
        "    enc_sentences, sentences, trees = batch_data\n",
        "    for enc_sentence, sentence, tree in zip(enc_sentences, sentences, trees):\n",
        "      env = DependencyParsingEnv(sentence, tree, max_steps_per_episode=500)\n",
        "      state = env.reset()[0]\n",
        "      while not env.parser.is_tree_final():\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward, done, truncated, _ = env.step(action)\n",
        "        state = next_state\n",
        "        if done or truncated or reward == -100:\n",
        "          #print(\"Gold Tree: \", tree)\n",
        "          #print(\"Parsed Tree: \", env.parser.arcs, \"\\n\")\n",
        "          count += 1\n",
        "          tot_loss = evaluateSingleTree(tree, env.parser.arcs)\n",
        "          break\n",
        "\n",
        "  # Print epoch summary\n",
        "  print(f'Epoch: {epoch}, UAS: {tot_loss/count}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5SkqEamWq7N",
        "outputId": "efc37630-5619-416d-9f00-5e9a7960672b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9746670018135641\n",
            "-40.241363040319904\n",
            "Epoch: 0, UAS: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir runs # runs is the name of the folder that has summaries saved"
      ],
      "metadata": {
        "id": "gbLY0mBpWXE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df25b5ae-67bc-4b4c-b3aa-8d5b7c3d99b8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-15 18:35:31.478663: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-15 18:35:31.478732: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-15 18:35:31.480146: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-15 18:35:32.629894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    }
  ]
}